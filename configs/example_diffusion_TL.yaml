# This is an example configuration file for fine-tuning a pre-trained diffusion model.

defaults:
  - data: mol_dataset
  - tasks: diffusion_pretrained
  - logger: wandb
  - trainer: default
  - hydra: default
  - _self_

# --- Experiment Tracking ---
name: "TL_exp"
tags: ["diffusion", "example", "baseline"]
seed: 42

# --- Task-Specific Overrides ---
tasks:
  chkpt_path: "edm_chem.pkl"  # Path to a pre-trained model checkpoint.

# --- Trainer Overrides ---
trainer:
  num_epochs: 50           
  lr: 0.0002    
  validation_interval: 3   
  output_path: "logs_TL"

# --- Data Overrides ---
data:
  batch_size: 64            # Change the batch size.
